\chapter{Introduction}
A computer program is said to learn from experience $E$ with respect to some class of tasks $T$ and performance measure $P$, if its performance at tasks in $T$ as measured by $P$, improves with experience $E$.\\
From that it is understood that machine learning is a form of inductive learning: it generalize from examples to a concept.
There is no certainty of correctness.

\section{Formalization of a machine learning problem}

	\subsection{Components of a machine learning problem}
	The components of a machine learning problem are:

	\begin{itemize}
		\item Task to be addressed by the system.
		\item Performance measure to evaluate the learned system.
		\item Training experience to train the learning system.
	\end{itemize}

	\subsection{Designing a machine learning system}
	The designing of a machine learning system can be described in a process that consist of different phases:

	\begin{enumerate}
		\item Formalize the learning task.
		\item Collect data.
		\item Extract features.
		\item Choose class of learning models.
		\item Train model.
		\item Evaluate model.
	\end{enumerate}

		\subsubsection{Formalize the learning task}
		To formalize the learning task means to define the task that should be addressed by learning system.
		This type of task, or learning problem, is often composed of a number of related tasks, sub-problems or side-tasks.
		It is also needed an appropriate performance measure for evaluating the learned system.
	
		\subsubsection{Collect data}
		To collect the data means to collect a set of training example in machine readable format.
		Data collection is often the most cumbersome part of the process, implying manual intervention especially in labelling examples for supervised learning.
		Recent approaches to the problem of data labelling try to make use of the availability of unlabelled data (semi-supervised learning it tries to learn using both supervised and unsupervised examples).

		\subsubsection{Extract features}
		A relevant set of features need to be extracted from the data in order to provide inputs to the learning system.
		Prior knowledge is usually necessary in order to choose the appropriate features for the task in mind.
		Extracting too few features can miss relevant information preventing the system from learning the task with reasonable performance.
		Extracting too many feature like can make the learning problem harder and require a number of examples greater than those available for training.
		Another problem arises when considering noisy features.
		It is noticeable that there is a need to choose the correct number and type of feature to permit a correct and efficient solution.

		\subsubsection{Choose class of learning models}
		Every problem has a class of learning model that is able to learn it best.
		A simple model like a linear classifier is easy to train but insufficient for non linearly separable data.
		A too complex model can memorize noise in training data failing to generalize to new examples.
		The algorithm need not to optimize but it needs to generalize, there can be outliers or labelling error.
		The more complex the model the more it will tend to overfit training noise.

		\subsubsection{Train model}
		Training a model implies searching though the space of possible models given the chosen model class.
		Such search typically aims at fitting the available training examples well according to the chosen performance measure.
		However the learned model should perform well on unseen data (generalization) and not simply memorize training examples (overfitting).
		Different techniques can be used to improve generalization, usually by trading off model complexity with training set fitting.

		\subsubsection{Evaluate model}
		The learned model is evaluated according to its ability to generalize to unseen examples.
		These example are collected in a test set.
		Evaluation can provide insights into the model weaknesses and suggest directions for refining and modifying it.
		Evaluation can imply comparing different models or learners in order to decide the best performing one.
		Statistical significance of observed differences between performance of different models should be assessed with appropriate statistical tests.


\section{Learning settings}

	\subsection{Supervised learning}
	The learner is provided with a set of inputs/output pairs $(x_i,y_i)\in X\times Y$.
	The learned model $f:x\rightarrow Y$ should map input examples into their output.
	A domain expert is typically involved in labelling input examples with output examples in the training set.

		\subsubsection{Tasks}
			
			\paragraph{Classification}
			\begin{itemize}
				\item Binary: assign an example to one of two possible classes often a positive and a negative one.
				\item Multiclass: assign an example to one of $n>2$ possible classes.
				\item Multilabel: assign an example to a subset $m\le n$ of the possible classes.
			\end{itemize}
	
			\paragraph{Regression}
			Assign a real value to an example.
	
			\paragraph{Ordinal regression or ranking}
			Order a set of examples according to their relative importance or quality with respect to the class.


	\subsection{Unsupervised learning}
	The learner is provided a set of input examples $x_i\in X$ with no labelling information.
	The learner models training examples, for examples clustering them together into clusters according to their similarity.

		\subsubsection{Tasks}

			\paragraph{Dimensionality reduction}
			Reduce dimensionality of the data maintaining as much information as possible.

			\paragraph{Clustering}
			Cluster data into homogeneous groups according to their similarity.

			\paragraph{Novelty detection}
			Detect novel examples which differ from the distribution of a certain set of data.


	\subsection{Semi-supervised learning}
	The learner is provided with a set of input output pairs $(x_i, y_i)\in X\times Y$.
	A typically much bigger additional set of unlabelled examples $x_i\in X$ is also provided.
	Like in supervised learning the learned model $f:X\rightarrow Y$ should map input examples into their output.
	Unlabelled data can be exploited to improve performance, by forcing the model to produce similar outputs for similar inputs, or by allowing to learn a better representation of examples.

	\subsection{Reinforcement learning}
	The learner is provided a set of possible states $S$ and for each state a set of possible actions $A$ moving it to a next state.
	In performing action $a$ from state $s$ the learner is provided an immediate reward $r(s,a)$.
	The task is to learn a policy allowing to choose for each state $s$ the action $a$ maximizing the overall reward.
	The learner has to deal with problems of delayed reward coming from future moves and trade-off between exploitation and exploration.
	Typical application include moving policies for robots and sequential scheduling problems in general.

\section{Probabilistic reasoning}
Probabilistic reasoning is the reasoning in presence of uncertainty.
It evaluates the effect of a certain piece of evidence on other related variables.
It estimates probabilities and relations between variables from a set of informations.
They depends on variables and their relations.

\section{Choice of learning algorithms}

	\subsection{Based on information available}
	\begin{itemize}
		\item Full knowledge of probability distributions of data: Bayesian decision theory.
		\item Form of probabilities known, parameters unknown: parameter estimation from training data.
		\item Form of probabilities unknown, training examples available: discriminative methods: do not model input data, learn a function predicting the desired output given the input.
		\item Form of probabilities unknown, training examples unavailable: unsupervised methods, cluster examples by similarity.
	\end{itemize}
